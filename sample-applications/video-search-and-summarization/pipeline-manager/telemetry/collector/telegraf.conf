# Configuration for telegraf agent
[agent]
  interval = "1s"
  round_interval = true
  metric_batch_size = 2000
  metric_buffer_limit = 20000
  collection_jitter = "0s"
  flush_interval = "1s"
  flush_jitter = "0s"
  precision = "1s"
  debug = false
  quiet = true
  logfile = ""

# Read metrics about cpu usage
[[inputs.cpu]]
  percpu = false
  totalcpu = true
  collect_cpu_time = false
  report_active = false
  core_tags = false
  fieldinclude = ["usage_user"]

# Read metrics about memory usage
[[inputs.mem]]
  fieldinclude = ["used_percent"]

# Read metrics from one or more commands that can output to stdout
[[inputs.exec]]
  commands = ["/app/read_cpu_freq.sh"]
  data_format = "influx"
  interval = "1s"

# Run executable as long-running input plugin
[[inputs.execd]]
  command = ["python3", "/app/qmassa_reader.py"]
  data_format = "influx"

# Read metrics about temperature
[[inputs.temp]]

# Process metrics using a Starlark script
[[processors.starlark]]
  namepass = ["temp"]
  source = '''
def apply(metric):
    return metric if metric.tags.get("sensor", "").startswith("coretemp_package_id_") else None
'''

[[inputs.file]]
  files = ["/app/.collector-signals/dataprep_embeddings_per_second.txt"]
  data_format = "value"
  data_type = "float"
  name_override = "dataprep_embeddings_per_second"

# Prometheus scrape endpoint for debugging/manual use
[[outputs.prometheus_client]]
  listen = ":9273"
  metric_version = 1
  path = "/metrics"
  collectors_exclude = ["gocollector", "process"]
  string_as_label = true
  export_timestamp = true

# WebSocket forwarder to Pipeline Manager telemetry relay
[[outputs.websocket]]
  url = "ws://pipeline-manager:3000/metrics/ws/collector"
  data_format = "json"
  read_timeout = "0s"
